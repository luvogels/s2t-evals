{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb8405-482b-4fed-ba91-54d58617037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687b493-8323-4870-abe4-81b1e140ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEval(BaseModel):\n",
    "    reference: str\n",
    "    hypothesis: str\n",
    "    title: Optional[str] = None\n",
    "        \n",
    "    def wer(self) -> float:\n",
    "        # Word Error Rate (WER)\n",
    "        return jiwer.wer(self.reference, self.hypothesis)\n",
    "        \n",
    "    def mer(self) -> float:\n",
    "        # Match Error Rate (MER)\n",
    "        return jiwer.mer(self.reference, self.hypothesis)\n",
    "\n",
    "    def wil(self) -> float:\n",
    "        # Word Information Lost (WIL)\n",
    "        return jiwer.wil(self.reference, self.hypothesis)\n",
    "\n",
    "    def wip(self) -> float:\n",
    "        # Word Information Preserved (WIP)\n",
    "        return jiwer.wip(self.reference, self.hypothesis)\n",
    "\n",
    "    def cer(self) -> float:\n",
    "        # Character Error Rate (CER)\n",
    "        return jiwer.cer(self.reference, self.hypothesis)\n",
    "\n",
    "    def explain(self) -> dict:\n",
    "        system_prompt = \"\"\"\n",
    "        You are a helpful and concise assistant specializing comparing and rating transcripts.\n",
    "        You will receive two texts, reference, the quality controlled ground truth and hypothesis and automated transcript created using asr\n",
    "        You will evaluate the hypothesis against the transcript using the following quality criteria:\n",
    "            * Accuracy, how precisely the transcription matches the actual spoken words.\n",
    "            * Completeness, Whether all relevant parts of the spoken content are included.\n",
    "            * Preservation of meaning, How well the original intent and ideas are retained.\n",
    "            * Readability, How easy the transcription is to read and understand.\n",
    "            * Style and tone retention, How well the speaker’s personal tone, expression, and manner of speaking are maintained.\n",
    "        \n",
    "        You will also include a explanation of the evaluation.\n",
    "        \"\"\"\n",
    "        \n",
    "        class QualityCriteria(BaseModel):\n",
    "            accuracy: Literal[1, 2, 3, 4, 5] # How precisely the transcription matches the actual spoken words.\n",
    "            completeness: Literal[1, 2, 3, 4, 5] # Whether all relevant parts of the spoken content are included.\n",
    "            preservation_of_meaning: Literal[1, 2, 3, 4, 5] # How well the original intent and ideas are retained.\n",
    "            readability: Literal[1, 2, 3, 4, 5] # How easy the transcription is to read and understand.\n",
    "            style_and_tone_retention: Literal[1, 2, 3, 4, 5] # How well the speaker’s personal tone, expression, and manner of speaking are maintained.\n",
    "            explanation: str\n",
    "            \n",
    "        ollama_model = OpenAIModel(\n",
    "            model_name='qwen3:30b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    "        )\n",
    "        agent = Agent(ollama_model, system_prompt=system_prompt, output_type=QualityCriteria,  instrument=True)\n",
    "        \n",
    "        result = agent.run_sync(f\"reference: {self.reference}, hypothesis: {self.hypothesis}\")\n",
    "        quality_criteria = result.output.model_dump()\n",
    "        return quality_criteria\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
